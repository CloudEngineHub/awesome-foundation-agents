# awesome-foundation-agents

[![PR Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen)](https://github.com/FoundationAgents/awesome-foundation-agents/pulls)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

We maintains a curated collection of papers exploring the path towards Foundation Agents, with a focus on formulating the core concepts and navigating the research landscape.

## Our Works Towards Foundation Agents

âœ¨âœ¨âœ¨ [Advances and Challenges in Foundation Agents]() (Paper)

<div style="display: flex; justify-content: space-between;">
    <img src="assets/brain.png" alt="The key of human brain." width="48%">
    <img src="assets/agent_framework.png" alt="The Framework of Foundation Agent" width="48%">
</div>

# Awesome Papers

<font size=5><center><b> Table of Contents </b> </center></font>
- [Core Components of Intelligent Agents](#core-components-of-intelligent-agents)
    - [Cognition](#cognition)
    - [Memory](#memory)
    - [Perception](#perception)
    - [World Model](#world-model)
    - [Action](#action)
    - [Reward](#reward)
    - [Emotion](#emotion)
- [Self-Enhancement in Intelligent Agents](#self-enhancement-in-intelligent-agents)
- [Collaborative and Evolutionary Intelligent Systems](#collaborative-and-evolutionary-intelligent-systems)
- [Building Safe and Beneficial AI](#building-safe-and-beneficial-ai)


# Core Components of Intelligent Agents

## Cognition

## Learning

* ðŸ”¥ **[MetaGPT](https://github.com/geekan/MetaGPT)** - *DeepWisdom, Jan 2025*  
  [![Paper](https://img.shields.io/badge/Paper-PDF-red)](https://openreview.net/forum?id=VtmBAGCN7o)
  [![Star](https://img.shields.io/github/stars/geekan/MetaGPT.svg?style=social&label=Star)](https://github.com/geekan/MetaGPT)
  [![Code](https://img.shields.io/badge/Code-Github-green)](https://github.com/geekan/MetaGPT)
  [![Demo](https://img.shields.io/badge/Demo-HuggingFace-blue)]()  
  > The Multi-Agent Framework: First AI Software Company, Towards Natural Language Programming

## Reasoning


## Memory

## Perception

## World Model

## Action
<div style="display: flex; justify-content: space-between;">
    <img src="assets/action.jpg" alt="The action." width="100%">
</div>

### Action Space:

### Language

#### Text

- **ReAct: Synergizing Reasoning and Acting in Language Models**, ICLR 2023, [[paper](https://arxiv.org/abs/2210.03629)] [[code](https://github.com/ysymyth/ReAct)]

- **AutoGPT: Build, Deploy, and Run AI Agents**, Github, [[code](https://github.com/Significant-Gravitas/AutoGPT)]

- **Reflexion: Language Agents with Verbal Reinforcement Learning**, NeurIPS 2023, [[paper](https://arxiv.org/abs/2303.11366)] [[code](https://github.com/noahshinn/reflexion)]

- **LLM+P: Empowering Large Language Models with Optimal Planning Proficiency**, arXiv 2023, [[paper](https://arxiv.org/abs/2304.11477)] [[code](https://github.com/Cranial-XIX/llm-pddl)]

#### Code

- **MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework**, ICLR 2023, [[paper](https://arxiv.org/abs/2308.00352)] [[code](https://github.com/geekan/MetaGPT)]

- **ChatDev: Communicative Agents for Software Development**, ACL 2024, [[paper](https://arxiv.org/abs/2307.07924)] [[code](https://github.com/OpenBMB/ChatDev)]

- **SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering**, NeurIPS 2025, [[paper](https://arxiv.org/abs/2405.15793)] [[code](https://github.com/SWE-agent/SWE-agent)]

- **OpenHands: An Open Platform for AI Software Developers as Generalist Agents**, arXiv 2024, [[paper](https://arxiv.org/abs/2407.16741)] [[code](https://github.com/All-Hands-AI/OpenHands)]
- 
#### Chat

- **Generative Agents: Interactive Simulacra of Human Behavior**, UIST 2023, [[paper](https://arxiv.org/abs/2304.03442)] [[code](https://github.com/joonspk-research/generative_agents)]

- **AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation**, COLM 2024, [[paper](https://arxiv.org/abs/2308.08155)] [[code](https://github.com/microsoft/autogen)]

### Digital

#### Game

- **MineDojo**, Details to be added

- **Voyager**, Details to be added

- **SwarmBrain**, Details to be added

- **JARVIS-1**, Details to be added

#### Multimodal

- **MM-ReAct**, Details to be added

- **ViperGPT**, Details to be added

- **Visual-ChatGPT**, Details to be added

- **HuggingGPT**, Details to be added

#### Web

- **WebGPT**, Details to be added

- **WebShop**, Details to be added

- **WebAgent**, Details to be added

- **Mind2Web**, Details to be added

#### GUI

- **Mobile-Agent**, Details to be added

- **AppAgent**, Details to be added

- **UFO**, Details to be added

- **OmniParser**, Details to be added

#### DB & KG

- **UnifiedSKG**, Details to be added

- **Pangu**, Details to be added

- **BIRD**, Details to be added

- **Spider 2.0**, Details to be added

- **Middleware**, Details to be added

### Physical

- **RT-1**, Details to be added

- **RT-2**, Details to be added

- **RT-X**, Details to be added

- **GR-2**, Details to be added

- **Ï€o**, Details to be added

- **Saycan**, Details to be added

- **VoxPoser**, Details to be added

- **EmbodiedGPT**, Details to be added

### Learning

### ICL (In-Context Learning)

#### Prompt

- **CoT**, Details to be added

- **ReAct**, arXiv, 2022 [[paper](https://arxiv.org/abs/2210.03629)]

- **Auto-CoT**, Details to be added

- **ToT**, Details to be added

- **GoT**, Details to be added

- **CoA**, Details to be added

#### Decompose

- **Least-to-Most**, Details to be added

- **HuggingGPT**, Details to be added

- **Plan-and-Solve**, Details to be added

- **ProgPrompt**, Details to be added

#### Role-play

- **Generative Agents**, Details to be added

- **MetaGPT**, Details to be added

- **ChatDev**, Details to be added

- **SWE-Agent**, Details to be added

#### Refine

- **Reflexion**, arXiv, 2023 [[paper](https://arxiv.org/abs/2303.11366)]

- **Self-refine**, Details to be added

- **GPTSwarm**, Details to be added

### PT & SFT (Pre-Training & Supervised Fine-Tuning)

#### Pre-Train

- **RT-1**, Details to be added

- **RT-2**, Details to be added

- **RT-X**, Details to be added

- **GR-2**, Details to be added

- **LAM**, Details to be added

#### SFT

- **LearnAct**, Details to be added

- **CogACT**, Details to be added

- **RT-H**, Details to be added

- **OpenVLA**, Details to be added

- **GR-2**, Details to be added

- **Ï€o**, Details to be added

- **UniAct**, Details to be added

### RL (Reinforcement Learning)

- **RLHF**, Details to be added

- **DPO**, Details to be added

- **RLFP**, Details to be added

- **ELLM**, Details to be added

- **GenSim**, Details to be added

- **LEA**, Details to be added

- **MLAQ**, Details to be added

- **KALM**, Details to be added

- **When2Ask**, Details to be added

- **Eureka**, Details to be added

- **ArCHer**, Details to be added

- **LLaRP**, Details to be added

- **GPTSwarm**, Details to be added

## Reward

## Emotion

# Self-Enhancement in Intelligent Agents

# Collaborative and Evolutionary Intelligent Systems

# Building Safe and Beneficial AI
